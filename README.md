# üß† Agente de IA Conversacional com RAG Integrado

<p align="center">
  <img src="image.png" alt="Demonstra√ß√£o do Agente de IA" width="400"/>
</p>

[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.12%2B-blue)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/fastapi-%3E%3D0.100-green)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/react-18-blue)](https://react.dev/)

**Autor:** Eduardo A.  
**Vers√£o:** 1.0.0  
**Data:** Junho 2025

---

## üìë Sum√°rio
- [Vis√£o Geral](#vis√£o-geral)
- [Arquitetura](#arquitetura)
- [Tecnologias](#tecnologias)
- [Instala√ß√£o](#instala√ß√£o)
- [Execu√ß√£o](#execu√ß√£o)
- [Exemplo de Uso](#exemplo-de-uso)
- [Contribui√ß√£o](#contribui√ß√£o)
- [Licen√ßa](#licen√ßa)

---

## üè∑Ô∏è Vis√£o Geral

Este projeto implementa um agente de IA conversacional baseado em **RAG (Retrieval-Augmented Generation)**, ideal para responder perguntas sobre produtos de um cat√°logo online. Desenvolvido em Python com **FastAPI**, **LangChain**, **ChromaDB** e **OpenAI API**, oferece uma solu√ß√£o escal√°vel, robusta e inteligente para atendimento ao cliente automatizado.

Principais benef√≠cios:
- Redu√ß√£o de custos operacionais
- Disponibilidade 24/7
- Consist√™ncia nas respostas
- Escalabilidade
- Gera√ß√£o de insights anal√≠ticos

> **Nota:** N√£o substitui atendimento humano em situa√ß√µes sens√≠veis. Utiliza a OpenAI API, podendo gerar custos por uso.

---

## üèóÔ∏è Arquitetura

### Backend (Python)
- **FastAPI**: framework web ass√≠ncrono
- **LangChain**: orquestra√ß√£o RAG
- **ChromaDB**: vector store para embeddings
- **Pydantic**: valida√ß√£o e serializa√ß√£o
- **OpenAI API**: gera√ß√£o de texto e embeddings

Estrutura principal:
```
backend/app/
‚îú‚îÄ‚îÄ main.py           # Entrypoint FastAPI
‚îú‚îÄ‚îÄ services/         # L√≥gica do agente
‚îú‚îÄ‚îÄ core/             # Configura√ß√µes e utilit√°rios
‚îú‚îÄ‚îÄ models/           # Modelos de dados
‚îú‚îÄ‚îÄ knowledge/        # Base de conhecimento
```

### Frontend (React + Vite)
- **React 18**
- **Tailwind CSS** + **Shadcn/UI**
- **Framer Motion** (anima√ß√µes)
- **Radix UI** (acessibilidade)
- **Axios** (requisi√ß√µes)

Estrutura principal:
```
frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ hooks/
```

---

## üõ†Ô∏è Tecnologias
- Python 3.12+
- FastAPI, LangChain, ChromaDB, Pydantic, OpenAI API
- Node.js 18+, React, Vite, Tailwind CSS, Shadcn/UI, Radix UI, Axios, pnpm

---

## ‚ö° Instala√ß√£o

### Backend
```bash
# Requisitos: Python 3.12+
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### Frontend
```bash
# Requisitos: Node.js 18+, pnpm
cd frontend
pnpm install
pnpm dev
```
Acesse: http://localhost:5173

---

## üöÄ Execu√ß√£o

- Backend: `uvicorn app.main:app --reload` (porta padr√£o: 8000)
- Frontend: `pnpm dev` (porta padr√£o: 5173)

Certifique-se de que o backend esteja ativo para o funcionamento do chatbot.

---

## üê≥ Execu√ß√£o com Docker e Docker Compose

Este projeto j√° est√° pronto para ser executado em containers Docker, tanto para o backend (FastAPI) quanto para o frontend (React + Vite).

### Pr√©-requisitos
- Docker
- Docker Compose

### Build e execu√ß√£o dos servi√ßos

No diret√≥rio raiz do projeto, execute:

```bash
docker compose up --build
```

- O backend estar√° dispon√≠vel em: http://localhost:8000
- O frontend estar√° dispon√≠vel em: http://localhost:5173

> **Aten√ß√£o:**
> O arquivo `pnpm-lock.yaml` √© essencial para o build do frontend. Certifique-se de que ele N√ÉO est√° listado no `.dockerignore` para evitar problemas de depend√™ncias.

### Parar os servi√ßos

```bash
docker compose down
```

---

## üí¨ Exemplo de Uso

### Endpoint de Chat
```
POST http://localhost:8000/api/v1/chat/message
Content-Type: application/json

{
  "message": "Quais smartphones est√£o dispon√≠veis?"
}
```
**Resposta:**
```json
{
  "response": "Atualmente temos os modelos X, Y e Z dispon√≠veis."
}
```

---

## üß† Funcionalidade de Mem√≥ria Persistente (SQLite)

Agora o agente possui mem√≥ria conversacional persistente! Todas as intera√ß√µes dos usu√°rios s√£o armazenadas automaticamente em um banco de dados SQLite (`backend/db/interactions.db`). Isso permite que o agente "lembre" do hist√≥rico de cada usu√°rio e utilize essas informa√ß√µes para respostas mais personalizadas.

**Como funciona:**
- Cada pergunta e resposta √© salva no banco, associada ao usu√°rio.
- O agente recupera as √∫ltimas intera√ß√µes do usu√°rio e utiliza como contexto para novas respostas.
- O hist√≥rico pode ser consultado diretamente via SQLite ou por endpoints customizados.

**Como visualizar o banco:**

Via terminal:
```bash
sqlite3 backend/db/interactions.db
```
No prompt do SQLite:
```sql
SELECT * FROM interactions;
```

Voc√™ tamb√©m pode usar ferramentas gr√°ficas como DB Browser for SQLite ou extens√µes do VS Code para explorar o banco.

---

## ü§ù Contribui√ß√£o

1. Fork este reposit√≥rio
2. Crie uma branch: `git checkout -b minha-feature`
3. Commit: `git commit -m "feat: minha feature"`
4. Push: `git push origin minha-feature`
5. Abra um Pull Request

Contribui√ß√µes, sugest√µes e issues s√£o bem-vindas!

---

## üìÑ Licen√ßa

Distribu√≠do sob licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes.

---

Desenvolvido por Eduardo A. ‚Äî TechStore
Powered by OpenAI, LangChain, FastAPI e Engenharia de Qualidade

